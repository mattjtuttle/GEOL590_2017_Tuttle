Notes regarding final project:

	-Need to generate easy to read and concise set of scripts
	-Generate a set of tools that is relatively robust for different/variations in data input
	-No single purpose scripts, need to develop tools. Tools are able to be used more than once.
	-Tool may be able to anticipate problems that your dataset doesn't have but other people might (e.g. dataset with missing values)


-Why are we interested in writing functions in data analysis?
	-It makes sense to create a function if we want something done the exact same way every single time

	Work-flow example:
	Raw data -> Exclude outliers -> make models of y vs x data -> extract slope, intercept, p-value -> Exclude lms w/ p > 0.05 -> make histogram of growth rates
	
		-Might make sense to take work-flow and encapsulate it into a function
			make_growth_hist(raw_data)
		
		-Split-apply-combine philosophy
		
			1.	Combine all raw data files
			2.	group_by(forest) %>%
					make_growth_hist() %>%
					print()
		
	-If you are going to be writing functions, you should be writing them well
		-Defensive programming:
			-Assume other users are going to be doing something stupid and try to account for that in your code
			
-Flow control:
	-Code that makes decisions about which code will get run
	-If statements are a form of flow control, likely most important
	-For loops are a second form. Piping tries to eliminate use of for loops and generally use of for loops in R is not advised.
	
-Error handling code:
	tryCatch()
		-Function used for error and warning handling
		
-Four loops:
	
	Pseudocode:
		a <- [1, 3, 7]
		b <- [5]

		Want to add 5 to every element of the above array, a:
		a+b

		Alternatively with a for loop:
		for each element of a {do (a[i] + b
			}
			
-As of right now, very few programming languages contain code that acts in the way that the tidyverse does. Python has some.

	More pseudocode:
		-This essentially "hacks" a way to perform split-apply-combine in other data languages
		
		process_data -> function(raw_data) {
							do all of the stuff you need to do
							return(processed_data)
							}
			
		for i in 1:length(raw_data_set) {
							p <- process_data(raw_data[i])
								processed_data[i] <- p
	
	
-Remember, throwing the browser() function in your code allows you to see under the hood at what is going on in your code.
-Data importing cheat sheet for dplyr should be consulted whenever you are looking to import data into R